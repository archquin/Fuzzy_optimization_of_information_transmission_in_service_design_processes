{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Abstract\n",
        "\n",
        "---\n",
        "\n",
        "GDFCM stands for gradient descent fuzzy cognition multiplex, and it is a holistic approach to analyze and optimize service design processes. The idea is to determine which *new* data points are relevant for the processes and to what degree; to do so, one needs to define metrics and use the input data for which these metrics are applied. This way, a deductive net is constructed that measures the processes' contribution as well as the services' expenses in a way that the design process has defined. However, there is no new data in this construct as it is strictly supervised and it is meant to determine the constituent process activation at each node; that is achievable by a simple FCM to. Moreover, a tensor is formed with **deep node** interactions which are then used to create process layers for trait/metric activation. Finally, it is possible to deduce whether a new data point fits in the model, to what degree, and for which layer; that is according to inputs and the output is the solution of a process design function, according to metrics.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "UR7hPj5KWD2z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWQZpBWgWBbi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "# ---------------- Synthetic dataset ----------------\n",
        "np.random.seed(42)\n",
        "N = 10000\n",
        "\n",
        "route_planning = pd.DataFrame({\n",
        "    'origin_x': np.random.uniform(0, 100, N),\n",
        "    'origin_y': np.random.uniform(0, 100, N),\n",
        "    'dest_x': np.random.uniform(0, 100, N),\n",
        "    'dest_y': np.random.uniform(0, 100, N),\n",
        "    'traffic_density': np.random.uniform(0, 1, N),\n",
        "    'road_type': np.random.choice([1, 2, 3], N),\n",
        "})\n",
        "route_planning['distance'] = np.sqrt((route_planning['dest_x'] - route_planning['origin_x'])**2 +\n",
        "                                     (route_planning['dest_y'] - route_planning['origin_y'])**2)\n",
        "speed_base = {1:50, 2:40, 3:30}\n",
        "route_planning['speed'] = route_planning['road_type'].map(speed_base) * np.random.uniform(0.8,1.2,N)\n",
        "route_planning['travel_time'] = (route_planning['distance']/route_planning['speed'])*60*\\\n",
        "                                (1+route_planning['traffic_density']*np.random.uniform(0.1,0.5,N))\n",
        "\n",
        "vehicle_assignment = pd.DataFrame({\n",
        "    'vehicle_capacity': np.random.randint(50,200,N),\n",
        "    'battery_level': np.random.uniform(0.3,1.0,N),\n",
        "    'delivery_size': np.random.randint(5,50,N),\n",
        "    'vehicle_type': np.random.choice([1,2],N),\n",
        "    'speed_factor': np.random.uniform(0.9,1.1,N),\n",
        "})\n",
        "vehicle_assignment['assigned_speed'] = route_planning['speed']*vehicle_assignment['speed_factor']\n",
        "vehicle_assignment['load_utilization'] = vehicle_assignment['delivery_size']/vehicle_assignment['vehicle_capacity']\n",
        "\n",
        "time_scheduling = pd.DataFrame({\n",
        "    'requested_time': np.random.randint(8,20,N),\n",
        "    'delivery_priority': np.random.randint(1,5,N),\n",
        "    'customer_patience': np.random.uniform(0,1,N),\n",
        "})\n",
        "time_scheduling['delay_probability'] = np.clip(\n",
        "    (route_planning['travel_time']/60)*(1+vehicle_assignment['load_utilization']*0.5)*np.random.uniform(0.8,1.2,N),\n",
        "    0,1\n",
        ")\n",
        "\n",
        "dynamic_rerouting = pd.DataFrame({\n",
        "    'current_x': np.random.uniform(0,100,N),\n",
        "    'current_y': np.random.uniform(0,100,N),\n",
        "    'traffic_updates': np.random.uniform(0,1,N),\n",
        "    'new_delivery_requests': np.random.randint(0,3,N),\n",
        "    'vehicle_status': np.random.choice([0,1],N),\n",
        "    'weather': np.random.choice([0,1],N),\n",
        "})\n",
        "dynamic_rerouting['congestion_score'] = dynamic_rerouting['traffic_updates'] + \\\n",
        "                                       dynamic_rerouting['new_delivery_requests']*0.5 + \\\n",
        "                                       dynamic_rerouting['weather']*0.5 + \\\n",
        "                                       (route_planning['travel_time']/route_planning['travel_time'].max())*0.5\n",
        "\n",
        "# ---------------- Combine and normalize ----------------\n",
        "datasets = [route_planning, vehicle_assignment, time_scheduling, dynamic_rerouting]\n",
        "dataset_dims = [df.shape[1] for df in datasets]\n",
        "max_dim = max(dataset_dims)\n",
        "\n",
        "padded_data = []\n",
        "for df in datasets:\n",
        "    arr = df.values\n",
        "    if arr.shape[1] < max_dim:\n",
        "        arr = np.hstack([arr, np.zeros((arr.shape[0], max_dim - arr.shape[1]))])\n",
        "    padded_data.append(arr)\n",
        "\n",
        "DATA_MATRIX = np.hstack(padded_data)\n",
        "DATA_MATRIX = (DATA_MATRIX - DATA_MATRIX.min(axis=0)) / (np.ptp(DATA_MATRIX, axis=0)+1e-8)\n",
        "\n",
        "def generate_targets(DATA_MATRIX, candidate_dims, D_graph):\n",
        "    targets = []\n",
        "    for node_idx in range(D_graph):\n",
        "        row = DATA_MATRIX[node_idx % len(DATA_MATRIX)]\n",
        "        node_targets = {}\n",
        "        for dim in candidate_dims:\n",
        "            if len(row) >= dim:\n",
        "                sampled = row[:dim]\n",
        "            else:\n",
        "                sampled = np.pad(row, (0, dim - len(row)), constant_values=0.5)\n",
        "            node_targets[dim] = sampled\n",
        "        targets.append(node_targets)\n",
        "    return targets\n",
        "candidate_dims = [6,6,6,6,6,6]#,6,6,6,6,6,6,6,6,6,6,6,6,]\n",
        "D_graph = 4\n",
        "synthetic_targets = generate_targets(DATA_MATRIX, candidate_dims, D_graph)\n",
        "\n",
        "# ---------------- Targets ----------------\n",
        "#candidate_dims = [6,6,6,6,6,6,6]#,6,6,6,6,6,6,6,6,6,6,6,6,]\n",
        "#D_graph = 4\n",
        "inner_archive_size = 120\n",
        "inner_offspring = 80\n",
        "outer_archive_size = 80\n",
        "outer_offspring = 80\n",
        "inner_iters_per_outer = 15\n",
        "outer_generations = 500\n",
        "outer_cost_limit = 1350\n",
        "inner_learning = 0.9\n",
        "seed = 42\n",
        "np.random.seed(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ---------------------- Seed ----------------------\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# ---------------------- PyTorch nets ----------------------\n",
        "class ParamNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
        "        self.out = nn.Linear(hidden_dim // 2, 3)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        raw = self.out(h)\n",
        "        w0 = F.softplus(raw[:, 0])\n",
        "        t0 = F.softplus(raw[:, 1])\n",
        "        u0 = torch.sigmoid(raw[:, 2])\n",
        "        w0 = 10.0 * (1.0 + (w0 - 1.0) * 0.2)\n",
        "        t0 = 100.0 * (1.0 + (t0 - 1.0) * 0.2)\n",
        "        u0 = 1.0 * (u0)\n",
        "        return torch.stack([w0, t0, u0], dim=1)\n",
        "\n",
        "\n",
        "class PatienceNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=32):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
        "        self.out = nn.Linear(hidden_dim // 2, 1)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        raw = self.out(h)\n",
        "        patience = torch.sigmoid(raw).squeeze(-1)\n",
        "        return patience\n",
        "\n",
        "\n",
        "# ---------------------- MetricsEvaluator (uses nets) ----------------------\n",
        "class MetricsEvaluator:\n",
        "    def __init__(self, data_matrix, param_net: ParamNet, patience_net: PatienceNet, device='cpu'):\n",
        "        self.data_matrix = data_matrix\n",
        "        self.num_features = data_matrix.shape[1]\n",
        "        self.device = device\n",
        "        self.param_net = param_net.to(self.device)\n",
        "        self.patience_net = patience_net.to(self.device)\n",
        "        self.param_net.eval()\n",
        "        self.patience_net.eval()\n",
        "\n",
        "    def compute_node_metrics(self, node_idx, y=None):\n",
        "        row = self.data_matrix[node_idx % self.data_matrix.shape[0]].astype(np.float32)\n",
        "        k = self.num_features\n",
        "        base = k // 3 if k >= 3 else 1\n",
        "        wait_cols = list(range(0, base))\n",
        "        thr_cols = list(range(base, 2 * base))\n",
        "        util_cols = list(range(2 * base, k))\n",
        "\n",
        "        wait_signal = float(np.mean(row[wait_cols])) if len(wait_cols) > 0 else 0.0\n",
        "        throughput_signal = float(np.mean(row[thr_cols])) if len(thr_cols) > 0 else 0.0\n",
        "        util_signal = float(np.mean(row[util_cols])) if len(util_cols) > 0 else 0.0\n",
        "\n",
        "        xt = torch.from_numpy(row).unsqueeze(0).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            params = self.param_net(xt).cpu().numpy().squeeze(0)\n",
        "            patience_val = float(self.patience_net(xt).cpu().numpy().squeeze(0))\n",
        "\n",
        "        W0_pred, T0_pred, U0_pred = float(params[0]), float(params[1]), float(params[2])\n",
        "\n",
        "        if y is None:\n",
        "            y = np.array([0.5, 0.5, 0.5])\n",
        "        else:\n",
        "            y = np.array(y[:3]) if len(y) >= 3 else np.pad(y, (0, 3 - len(y)), constant_values=0.5)\n",
        "\n",
        "        wait = W0_pred * (1 + 1.2 * wait_signal + 0.8 * y[0])\n",
        "        throughput = T0_pred * (1 + 1.1 * throughput_signal + 0.6 * y[1] - 0.4 * wait_signal)\n",
        "        util = U0_pred + 0.8 * util_signal + 0.6 * y[2]\n",
        "\n",
        "        wait = float(np.clip(wait, 0, 100))\n",
        "        throughput = float(np.clip(throughput, 0, 150))\n",
        "        util = float(np.clip(util, 0, 1))\n",
        "\n",
        "        score = -wait + throughput + util\n",
        "\n",
        "        return {\n",
        "            'wait': wait,\n",
        "            'throughput': throughput,\n",
        "            'util': util,\n",
        "            'score': score,\n",
        "            'W0': W0_pred,\n",
        "            'T0': T0_pred,\n",
        "            'U0': U0_pred,\n",
        "            'patience': patience_val\n",
        "        }\n",
        "\n",
        "\n",
        "# ---------------------- InterLayer ----------------------\n",
        "class InterLayer:\n",
        "    def __init__(self, D_graph, max_inner_dim, edge_threshold=0.02, seed=42):\n",
        "        np.random.seed(seed)\n",
        "        self.D_graph = D_graph\n",
        "        self.max_input = 2 * max_inner_dim\n",
        "        self.weights = {}\n",
        "        self.bias = {}\n",
        "        for i in range(D_graph):\n",
        "            for j in range(D_graph):\n",
        "                if i == j:\n",
        "                    continue\n",
        "                self.weights[(i, j)] = np.random.uniform(-0.6, 0.6, (max_inner_dim, self.max_input))\n",
        "                self.bias[(i, j)] = np.random.uniform(-0.3, 0.3, max_inner_dim)\n",
        "        self.edge_threshold = edge_threshold\n",
        "\n",
        "    def compute_edge_activation(self, i, j, nested_reps):\n",
        "        concat = np.concatenate([nested_reps[i], nested_reps[j]])\n",
        "        if len(concat) < self.max_input:\n",
        "            concat = np.pad(concat, (0, self.max_input - len(concat)))\n",
        "        else:\n",
        "            concat = concat[:self.max_input]\n",
        "        v = self.weights[(i, j)].dot(concat) + self.bias[(i, j)]\n",
        "        return 1 / (1 + np.exp(-v))\n",
        "\n",
        "    def build_inter_activations(self, Gmat, nested_reps):\n",
        "        acts = {}\n",
        "        for i in range(self.D_graph):\n",
        "            for j in range(self.D_graph):\n",
        "                if i == j:\n",
        "                    continue\n",
        "                if abs(Gmat[i, j]) > self.edge_threshold:\n",
        "                    acts[(i, j)] = self.compute_edge_activation(i, j, nested_reps)\n",
        "        return acts\n",
        "\n",
        "    @staticmethod\n",
        "    def pairwise_squared_corr(acts):\n",
        "        if len(acts) < 2:\n",
        "            return 0.0\n",
        "        A = np.stack(list(acts.values()))\n",
        "        A_cent = A - A.mean(axis=1, keepdims=True)\n",
        "        stds = np.sqrt((A_cent ** 2).sum(axis=1) / (A.shape[1] - 1) + 1e-12)\n",
        "        cov = A_cent.dot(A_cent.T) / (A.shape[1] - 1)\n",
        "        denom = np.outer(stds, stds) + 1e-12\n",
        "        corr = cov / denom\n",
        "        np.fill_diagonal(corr, 0)\n",
        "        return (corr ** 2).sum()\n",
        "\n",
        "    def mi_for_graph(self, Gmat, nested_reps):\n",
        "        acts = self.build_inter_activations(Gmat, nested_reps)\n",
        "        if len(acts) == 0:\n",
        "            return 0.0\n",
        "        return float(self.pairwise_squared_corr(acts))\n",
        "\n",
        "\n",
        "# ---------------------- UnifiedACORMultiplex ----------------------\n",
        "class UnifiedACORMultiplex:\n",
        "    def __init__(self, candidate_dims, D_graph, inner_archive_size, inner_offspring,\n",
        "                 outer_archive_size, outer_offspring, synthetic_targets,\n",
        "                 inner_learning, causal_flag, metrics_evaluator: MetricsEvaluator):\n",
        "        self.candidate_dims = candidate_dims\n",
        "        self.D_graph = D_graph\n",
        "        self.inner_archive_size = inner_archive_size\n",
        "        self.inner_offspring = inner_offspring\n",
        "        self.outer_archive_size = outer_archive_size\n",
        "        self.outer_offspring = outer_offspring\n",
        "        self.synthetic_targets = synthetic_targets\n",
        "        self.inner_learning = inner_learning\n",
        "        self.causal_flag = causal_flag\n",
        "\n",
        "        self.nested_reps = [np.zeros(max(candidate_dims)) for _ in range(D_graph)]\n",
        "        self.best_dim_per_node = [candidate_dims[0] for _ in range(D_graph)]\n",
        "        self.inter_layer = InterLayer(D_graph, max_inner_dim=max(candidate_dims))\n",
        "        self.chosen_Gmat = np.random.uniform(-0.5, 0.5, (D_graph, D_graph))\n",
        "        np.fill_diagonal(self.chosen_Gmat, 0)\n",
        "        self.l2_before = []\n",
        "        self.l2_after = []\n",
        "\n",
        "        self.metrics_evaluator = metrics_evaluator\n",
        "\n",
        "    @staticmethod\n",
        "    def fcm_propagate(x, W, steps=30):\n",
        "        y = x.copy()\n",
        "        for _ in range(steps):\n",
        "            y = 1 / (1 + np.exp(- (W.dot(y) + x)))\n",
        "        return y\n",
        "\n",
        "    @staticmethod\n",
        "    def behavioral_update(W, y, alpha=0.6, lr=0.1, decay=0.01, causal_mask=None, eps=1e-6):\n",
        "        C = y.copy()\n",
        "        D = np.abs(y - np.mean(y))\n",
        "        S = alpha * C + (1 - alpha) * D\n",
        "        RC = (y - np.mean(y)) / (np.std(y) + eps)\n",
        "        RI = (S - np.mean(S)) / (np.std(S) + eps)\n",
        "        delta = lr * np.outer(RC, RI) - decay * W\n",
        "        np.fill_diagonal(delta, 0)\n",
        "        W_new = W + delta\n",
        "        if causal_mask is not None:\n",
        "            W_new = np.sign(causal_mask) * np.abs(W_new)\n",
        "        np.clip(W_new, -1, 1, out=W_new)\n",
        "        np.fill_diagonal(W_new, 0)\n",
        "        return W_new\n",
        "\n",
        "    def run_inner(self, node_idx, target, D_fcm):\n",
        "        self.l2_before.append(np.linalg.norm(self.nested_reps[node_idx] - target))\n",
        "        metrics_info = self.metrics_evaluator.compute_node_metrics(node_idx, y=self.nested_reps[node_idx])\n",
        "        patience = metrics_info.get('patience', 0.5)\n",
        "\n",
        "        base_iters = globals().get('inner_iters_per_outer', 15)\n",
        "        iters = max(2, int(round(base_iters * (1.0 + patience))))\n",
        "        lr_scale = max(0.1, 1.0 - 0.6 * patience)\n",
        "        inner_lr = self.inner_learning * lr_scale\n",
        "\n",
        "        x = target.copy()\n",
        "        W = np.random.uniform(-0.6, 0.6, (D_fcm, D_fcm))\n",
        "        np.fill_diagonal(W, 0)\n",
        "\n",
        "        for it in range(iters):\n",
        "            y = self.fcm_propagate(x, W)\n",
        "            W = self.behavioral_update(W, y, lr=0.1 * lr_scale)\n",
        "            x += inner_lr * (target - y)\n",
        "            x = np.clip(x, 0, 1)\n",
        "\n",
        "        self.nested_reps[node_idx] = y\n",
        "        self.l2_after.append(np.linalg.norm(y - target))\n",
        "\n",
        "        mi_score = self.inter_layer.mi_for_graph(self.chosen_Gmat, self.nested_reps)\n",
        "        return x, W, y, mi_score\n",
        "\n",
        "    def run_outer(self):\n",
        "        node_metrics_list = []\n",
        "        raw_scores = []\n",
        "        for i, y in enumerate(self.nested_reps):\n",
        "            metrics = self.metrics_evaluator.compute_node_metrics(i, y=y)\n",
        "            node_metrics_list.append(metrics)\n",
        "            raw_scores.append(metrics['score'])\n",
        "        raw_scores = np.array(raw_scores)\n",
        "        total_raw = raw_scores.sum()\n",
        "        outer_cost_limit = globals().get('outer_cost_limit', 1350)\n",
        "        if total_raw > outer_cost_limit:\n",
        "            scale_factor = outer_cost_limit / total_raw\n",
        "            scaled_scores = raw_scores * scale_factor\n",
        "            for i, s in enumerate(scaled_scores):\n",
        "                node_metrics_list[i]['score'] = s\n",
        "            total_capped = scaled_scores.sum()\n",
        "        else:\n",
        "            total_capped = total_raw\n",
        "        return node_metrics_list, total_capped\n",
        "\n",
        "    def run(self, outer_generations= None):\n",
        "        if outer_generations is None:\n",
        "            outer_generations = globals().get('outer_generations', 500)\n",
        "        final_metrics_list = None\n",
        "        for gen in range(outer_generations):\n",
        "            mi_scores = []\n",
        "            for node_idx in range(self.D_graph):\n",
        "                dim = self.best_dim_per_node[node_idx]\n",
        "                target = self.synthetic_targets[node_idx][dim]\n",
        "                _, _, _, mi_score = self.run_inner(node_idx, target, dim)\n",
        "                mi_scores.append(mi_score)\n",
        "            metrics_list, capped_score = self.run_outer()\n",
        "\n",
        "            print(f\"\\n--- Generation {gen} Metrics ---\")\n",
        "            for i, m in enumerate(metrics_list):\n",
        "                metric_str = \" | \".join([f\"{k}: {v:.2f}\" for k, v in m.items() if k in ('wait','throughput','util','score')])\n",
        "                print(f\"Node {i} | {metric_str} | patience: {metrics_list[i]['patience']:.2f}\")\n",
        "            print(f\"Outer Score (global capped): {capped_score:.3f}\")\n",
        "\n",
        "            final_metrics_list = metrics_list\n",
        "\n",
        "        return final_metrics_list\n",
        "\n",
        "    # ---------------- PLOTTING ----------------\n",
        "    def plot_nested_activations(self):\n",
        "        plt.figure(figsize=(12, 3))\n",
        "        for i, rep in enumerate(self.nested_reps):\n",
        "            plt.subplot(1, self.D_graph, i + 1)\n",
        "            plt.bar(range(len(rep)), rep, color=plt.cm.plasma(rep))\n",
        "            plt.ylim(0, 1)\n",
        "            plt.title(f\"Node {i+1} Activations\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_outer_fuzzy_graph(self):\n",
        "        G = nx.DiGraph()\n",
        "        for i in range(self.D_graph):\n",
        "            G.add_node(i)\n",
        "        for i in range(self.D_graph):\n",
        "            for j in range(self.D_graph):\n",
        "                if i != j and abs(self.chosen_Gmat[i, j]) > 0.02:\n",
        "                    G.add_edge(i, j, weight=self.chosen_Gmat[i, j])\n",
        "        node_sizes = [self.best_dim_per_node[i] * 200 for i in range(self.D_graph)]\n",
        "        edge_colors = ['green' if d['weight'] > 0 else 'red' for _, _, d in G.edges(data=True)]\n",
        "        edge_widths = [abs(d['weight']) * 3 for _, _, d in G.edges(data=True)]\n",
        "        pos = nx.circular_layout(G)\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        nx.draw(G, pos, node_size=node_sizes, node_color='skyblue', edge_color=edge_colors,\n",
        "                width=edge_widths, arrows=True, with_labels=True)\n",
        "        plt.title(\"Outer Fuzzy Multiplex Graph\")\n",
        "        plt.show()\n",
        "\n",
        "    def plot_nested_vs_target(self):\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        for i in range(self.D_graph):\n",
        "            best_dim = self.best_dim_per_node[i]\n",
        "            y_actual = self.nested_reps[i]\n",
        "            y_target = self.synthetic_targets[i][best_dim]\n",
        "            if len(y_target) < len(y_actual):\n",
        "                y_target = np.pad(y_target, (0, len(y_actual) - len(y_target)), \"constant\")\n",
        "            elif len(y_target) > len(y_actual):\n",
        "                y_target = y_target[:len(y_actual)]\n",
        "            plt.subplot(1, self.D_graph, i + 1)\n",
        "            plt.plot(range(len(y_actual)), y_actual, 'o-', label='FCM Output')\n",
        "            plt.plot(range(len(y_target)), y_target, 'x--', label='Target')\n",
        "            plt.ylim(0, 1.1)\n",
        "            plt.title(f\"Node {i+1} | Dim {best_dim}\")\n",
        "            if i == 0:\n",
        "                plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def collect_pointwise_minmax_elite(self, node_idx, dim, top_k=10):\n",
        "        reps = []\n",
        "        base = self.nested_reps[node_idx]\n",
        "        for _ in range(top_k):\n",
        "            reps.append(np.clip(base + np.random.normal(0, 0.05, len(base)), 0, 1))\n",
        "        reps = np.array(reps)\n",
        "        return reps.min(axis=0), reps.max(axis=0)\n",
        "\n",
        "    def plot_pointwise_minmax_elite(self, top_k=21):\n",
        "        plt.figure(figsize=(14, 3))\n",
        "        for i in range(self.D_graph):\n",
        "            dim = self.best_dim_per_node[i]\n",
        "            y_min, y_max = self.collect_pointwise_minmax_elite(i, dim, top_k)\n",
        "            y_sel = self.nested_reps[i]\n",
        "            y_true = self.synthetic_targets[i][dim]\n",
        "            if len(y_true) < len(y_sel):\n",
        "                y_true = np.pad(y_true, (0, len(y_sel) - len(y_true)), \"constant\")\n",
        "            elif len(y_true) > len(y_sel):\n",
        "                y_true = y_true[:len(y_sel)]\n",
        "            x = np.arange(len(y_min))\n",
        "            plt.subplot(1, self.D_graph, i + 1)\n",
        "            plt.fill_between(x, y_min, y_max, color='skyblue', alpha=0.4, label='Elite Interval')\n",
        "            plt.plot(x, y_sel, 'k-', lw=2, label='Estimated Activation')\n",
        "            plt.plot(x, y_true, 'r--', lw=2, label='True Activation')\n",
        "            plt.ylim(0, 1.05)\n",
        "            plt.title(f\"Node {i+1} | Dim {dim}\")\n",
        "            if i == 0:\n",
        "                plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# ---------------------- Example main ----------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # The script expects the following global variables to be provided by the environment\n",
        "    required = ['DATA_MATRIX', 'candidate_dims', 'D_graph', 'inner_archive_size', 'inner_offspring',\n",
        "                'outer_archive_size', 'outer_offspring', 'synthetic_targets', 'inner_learning']\n",
        "    missing = [v for v in required if v not in globals()]\n",
        "    if missing:\n",
        "        raise RuntimeError(f\"Missing required globals in environment: {missing}.\\nPlease define DATA_MATRIX, candidate_dims, D_graph, synthetic_targets, etc., before running this script.\")\n",
        "\n",
        "    input_dim = DATA_MATRIX.shape[1]\n",
        "    param_net = ParamNet(input_dim=input_dim, hidden_dim=64)\n",
        "    patience_net = PatienceNet(input_dim=input_dim, hidden_dim=32)\n",
        "\n",
        "    metrics_evaluator = MetricsEvaluator(DATA_MATRIX, param_net, patience_net, device='cpu')\n",
        "\n",
        "    optimizer = UnifiedACORMultiplex(candidate_dims, D_graph,\n",
        "                                     inner_archive_size, inner_offspring,\n",
        "                                     outer_archive_size, outer_offspring,\n",
        "                                     synthetic_targets,\n",
        "                                     inner_learning, causal_flag=False,\n",
        "                                     metrics_evaluator=metrics_evaluator)\n",
        "\n",
        "    metrics_list = optimizer.run(outer_generations=globals().get('outer_generations', 20))\n",
        "\n",
        "    optimizer.plot_pointwise_minmax_elite(top_k=21)\n",
        "    optimizer.plot_nested_activations()\n",
        "    optimizer.plot_outer_fuzzy_graph()\n",
        "    optimizer.plot_nested_vs_target()\n"
      ],
      "metadata": {
        "id": "w4fvke1OWbsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "candidate_dims = [6] * 3\n",
        "D_graph = 4\n",
        "\n",
        "inner_archive_size = 80\n",
        "inner_offspring = 40\n",
        "outer_archive_size = 40\n",
        "outer_offspring = 40\n",
        "inner_iters_per_outer = 50\n",
        "outer_generations = 101\n",
        "outer_cost_limit = 1000\n",
        "inner_learning = 0.1\n",
        "gamma_interlayer = 0.3\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ---------------------- Neural Nets for Metric Estimation ----------------------\n",
        "class ParamNet(nn.Module):\n",
        "    \"\"\"Estimates W0, T0, U0 from input features.\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
        "        self.out = nn.Linear(hidden_dim // 2, 3)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        raw = self.out(h)\n",
        "        w0 = F.softplus(raw[:, 0])\n",
        "        t0 = F.softplus(raw[:, 1])\n",
        "        u0 = torch.sigmoid(raw[:, 2])\n",
        "        w0 = 10.0 * (1.0 + 0.2 * (w0 - 1.0))\n",
        "        t0 = 100.0 * (1.0 + 0.2 * (t0 - 1.0))\n",
        "        u0 = 1.0 * u0\n",
        "        return torch.stack([w0, t0, u0], dim=1)\n",
        "\n",
        "\n",
        "class PatienceNet(nn.Module):\n",
        "    \"\"\"Estimates patience metric from input features.\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=32):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
        "        self.out = nn.Linear(hidden_dim // 2, 1)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        raw = self.out(h)\n",
        "        patience = torch.sigmoid(raw).squeeze(-1)\n",
        "        return patience\n",
        "\n",
        "\n",
        "# ---------------------- MetricsEvaluator using Neural Estimators ----------------------\n",
        "class MetricsEvaluator:\n",
        "    def __init__(self, data_matrix, param_net: ParamNet, patience_net: PatienceNet, device='cpu'):\n",
        "        self.data_matrix = data_matrix.astype(np.float32)\n",
        "        self.num_features = data_matrix.shape[1]\n",
        "        self.device = device\n",
        "        self.param_net = param_net.to(self.device)\n",
        "        self.patience_net = patience_net.to(self.device)\n",
        "        self.param_net.eval()\n",
        "        self.patience_net.eval()\n",
        "\n",
        "    def compute_node_metrics(self, node_idx, y=None):\n",
        "        \"\"\"Compute metrics for a given node using neural estimators.\"\"\"\n",
        "        row = self.data_matrix[node_idx % self.data_matrix.shape[0]]\n",
        "        row_tensor = torch.from_numpy(row).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            params = self.param_net(row_tensor).cpu().numpy().squeeze(0)\n",
        "            patience_val = float(self.patience_net(row_tensor).cpu().numpy().squeeze(0))\n",
        "\n",
        "        W0_pred, T0_pred, U0_pred = float(params[0]), float(params[1]), float(params[2])\n",
        "\n",
        "        # fallback\n",
        "        if y is None:\n",
        "            y = np.array([0.5, 0.5, 0.5])\n",
        "        else:\n",
        "            y = np.array(y[:3]) if len(y) >= 3 else np.pad(y, (0, 3-len(y)), constant_values=0.5)\n",
        "\n",
        "        # Compute signals\n",
        "        k = self.num_features\n",
        "        base = max(1, k // 3)\n",
        "        wait_signal = np.mean(row[0:base])\n",
        "        throughput_signal = np.mean(row[base:2*base])\n",
        "        util_signal = np.mean(row[2*base:k])\n",
        "\n",
        "        # Metrics\n",
        "        wait = np.clip(W0_pred * (1 + 1.2 * wait_signal + 0.8 * y[0]), 0, 100)\n",
        "        throughput = np.clip(T0_pred * (1 + 1.1 * throughput_signal + 0.6 * y[1] - 0.4 * wait_signal), 0, 150)\n",
        "        util = np.clip(U0_pred + 0.8 * util_signal + 0.6 * y[2], 0, 1)\n",
        "\n",
        "        # Score combining all\n",
        "        score = -wait + throughput + util + patience_val\n",
        "\n",
        "        return {\n",
        "            'wait': float(wait),\n",
        "            'throughput': float(throughput),\n",
        "            'util': float(util),\n",
        "            'patience': patience_val,\n",
        "            'score': float(score),\n",
        "            'W0': W0_pred,\n",
        "            'T0': T0_pred,\n",
        "            'U0': U0_pred\n",
        "        }\n",
        "\n",
        "# ---------------- INTER-LAYER MUTUAL INFORMATION ----------------\n",
        "class InterLayer:\n",
        "    def __init__(self, D_graph, max_inner_dim, inter_dim=None, edge_threshold=0.02, gamma=1.0, seed=42):\n",
        "        np.random.seed(seed)\n",
        "        self.D_graph = D_graph\n",
        "        self.max_input = 2*max_inner_dim\n",
        "        self.edge_threshold = edge_threshold\n",
        "        self.gamma = gamma\n",
        "        self.inter_dim = inter_dim if inter_dim is not None else max_inner_dim\n",
        "        self.weights = {(i,j): np.random.uniform(-0.6,0.6,(self.inter_dim,self.max_input))\n",
        "                        for i in range(D_graph) for j in range(D_graph) if i!=j}\n",
        "        self.bias = {(i,j): np.random.uniform(-0.3,0.3,self.inter_dim)\n",
        "                     for i in range(D_graph) for j in range(D_graph) if i!=j}\n",
        "\n",
        "    def compute_edge_activation(self, i, j, nested_reps):\n",
        "        concat = np.concatenate([nested_reps[i], nested_reps[j]])\n",
        "        concat = np.pad(concat, (0, max(0,self.max_input-len(concat))))[:self.max_input]\n",
        "        v = self.weights[(i,j)].dot(concat) + self.bias[(i,j)]\n",
        "        return 1/(1+np.exp(-v))\n",
        "\n",
        "    def build_activations(self, Gmat, nested_reps):\n",
        "        acts = {}\n",
        "        for i in range(self.D_graph):\n",
        "            for j in range(self.D_graph):\n",
        "                if i==j: continue\n",
        "                if abs(Gmat[i,j])>self.edge_threshold:\n",
        "                    acts[(i,j)] = self.compute_edge_activation(i,j,nested_reps)\n",
        "        return acts\n",
        "\n",
        "    @staticmethod\n",
        "    def pairwise_squared_corr(acts):\n",
        "        if len(acts)<2: return 0.0\n",
        "        A = np.stack(list(acts.values()))\n",
        "        A_centered = A - A.mean(axis=1,keepdims=True)\n",
        "        stds = np.sqrt(np.sum(A_centered**2,axis=1)/(A.shape[1]-1) + 1e-12)\n",
        "        cov = A_centered @ A_centered.T / (A.shape[1]-1)\n",
        "        corr = cov / (np.outer(stds,stds)+1e-12)\n",
        "        np.fill_diagonal(corr,0)\n",
        "        return float((corr**2).sum())\n",
        "\n",
        "    def mi_for_graph(self, Gmat, nested_reps):\n",
        "        acts = self.build_activations(Gmat,nested_reps)\n",
        "        if not acts: return 0.0\n",
        "        return self.gamma * self.pairwise_squared_corr(acts)\n",
        "\n",
        "# ---------------- UNIFIED ACOR MULTIPLEX ----------------\n",
        "class GDFCM:\n",
        "    def __init__(self, candidate_dims, D_graph, inner_archive_size, inner_offspring,\n",
        "                 outer_archive_size, outer_offspring, synthetic_targets, inner_learning,\n",
        "                 gamma_interlayer=1.0, causal_flag=True):\n",
        "        self.candidate_dims = candidate_dims\n",
        "        self.D_graph = D_graph\n",
        "        self.inner_archive_size = inner_archive_size\n",
        "        self.inner_offspring = inner_offspring\n",
        "        self.outer_archive_size = outer_archive_size\n",
        "        self.outer_offspring = outer_offspring\n",
        "        self.synthetic_targets = synthetic_targets\n",
        "        self.inner_learning = inner_learning\n",
        "        self.causal_flag = causal_flag\n",
        "\n",
        "        self.nested_reps = [np.zeros(max(candidate_dims)) for _ in range(D_graph)]\n",
        "        self.best_dim_per_node = [candidate_dims[0] for _ in range(D_graph)]\n",
        "        self.inter_layer = InterLayer(D_graph, max_inner_dim=max(candidate_dims), gamma=gamma_interlayer)\n",
        "        self.chosen_Gmat = np.random.uniform(-0.5,0.5,(D_graph,D_graph))\n",
        "        np.fill_diagonal(self.chosen_Gmat,0)\n",
        "        self.l2_before, self.l2_after = [], []\n",
        "\n",
        "    # ---------- INNER LOOP (FCM) ----------\n",
        "    def run_inner(self, node_idx, target, D_fcm, steps=100, lr_x=0.001, lr_W=0.001):\n",
        "        x = target.copy()\n",
        "        W = np.random.uniform(-0.6,0.6,(D_fcm,D_fcm))\n",
        "        np.fill_diagonal(W,0)\n",
        "        self.l2_before.append(np.linalg.norm(self.nested_reps[node_idx]-target))\n",
        "\n",
        "        for _ in range(steps):\n",
        "            z = W.dot(x)\n",
        "            Theta_grad_z = 2*z - target\n",
        "            Theta_grad_x = Theta_grad_z @ W + 0.5*(x+1)**2\n",
        "            Theta_grad_W = np.outer(Theta_grad_z,x)\n",
        "\n",
        "            x -= lr_x * np.clip(Theta_grad_x,-0.05,0.05)\n",
        "            x = np.clip(x,0,1)\n",
        "            W -= lr_W * np.clip(Theta_grad_W,-0.01,0.01)\n",
        "            np.fill_diagonal(W,0)\n",
        "            W = np.clip(W,-1,1)\n",
        "\n",
        "        self.nested_reps[node_idx] = x\n",
        "        self.l2_after.append(np.linalg.norm(x-target))\n",
        "        mi_score = self.inter_layer.mi_for_graph(self.chosen_Gmat,self.nested_reps)\n",
        "        return x, W, x, mi_score\n",
        "\n",
        "    # ---------- OUTER LOOP ----------\n",
        "    def run_outer(self):\n",
        "        # Create MetricsEvaluator with the neural nets\n",
        "        metrics_evaluator = MetricsEvaluator(DATA_MATRIX, param_net, patience_net)\n",
        "        node_metrics_list = []\n",
        "        raw_scores = []\n",
        "\n",
        "        for i, y in enumerate(self.nested_reps):\n",
        "            metrics = metrics_evaluator.compute_node_metrics(i, y=y)\n",
        "            node_metrics_list.append(metrics)\n",
        "            raw_scores.append(metrics['score'])\n",
        "\n",
        "        raw_scores = np.array(raw_scores)\n",
        "        total_raw = raw_scores.sum()\n",
        "        if total_raw > outer_cost_limit:\n",
        "            scale_factor = outer_cost_limit / total_raw\n",
        "            for i, s in enumerate(raw_scores * scale_factor):\n",
        "                node_metrics_list[i]['score'] = s\n",
        "            total_capped = (raw_scores * scale_factor).sum()\n",
        "        else:\n",
        "            total_capped = total_raw\n",
        "        return node_metrics_list, total_capped\n",
        "\n",
        "    # ---------- FULL RUN ----------\n",
        "    def run(self, outer_generations=outer_generations):\n",
        "        final_metrics = None\n",
        "        for gen in range(outer_generations):\n",
        "            mi_scores = []\n",
        "            for node_idx in range(self.D_graph):\n",
        "                dim = self.best_dim_per_node[node_idx]\n",
        "                target = self.synthetic_targets[node_idx][dim]\n",
        "                _, _, _, mi_score = self.run_inner(node_idx,target,dim)\n",
        "                mi_scores.append(mi_score)\n",
        "\n",
        "            metrics_list, capped_score = self.run_outer()\n",
        "            print(f\"\\n--- Generation {gen} Metrics ---\")\n",
        "            for i,m in enumerate(metrics_list):\n",
        "                print(f\"Node {i} | \" + \" | \".join([f\"{k}: {v:.2f}\" for k,v in m.items()]))\n",
        "            print(f\"Outer Score (capped): {capped_score:.3f}\")\n",
        "            final_metrics = metrics_list\n",
        "        return final_metrics\n",
        "\n",
        "    # ---------- VISUALIZATIONS ----------\n",
        "    def plot_pointwise_minmax_elite(self, top_k=21):\n",
        "        plt.figure(figsize=(14,3))\n",
        "        for i in range(self.D_graph):\n",
        "            base = self.nested_reps[i]\n",
        "            reps = np.clip(base + np.random.normal(0,0.05,(top_k,len(base))),0,1)\n",
        "            y_min, y_max = reps.min(axis=0), reps.max(axis=0)\n",
        "            y_sel = base\n",
        "            y_true = self.synthetic_targets[i][self.best_dim_per_node[i]]\n",
        "            if len(y_true)<len(y_sel):\n",
        "                y_true = np.pad(y_true,(0,len(y_sel)-len(y_true)),\"constant\")\n",
        "            else:\n",
        "                y_true = y_true[:len(y_sel)]\n",
        "\n",
        "            plt.subplot(1,self.D_graph,i+1)\n",
        "            plt.fill_between(range(len(y_min)),y_min,y_max,color='skyblue',alpha=0.4,label='Elite Interval')\n",
        "            plt.plot(y_sel,'k-',lw=2,label='Estimated')\n",
        "            plt.plot(y_true,'r--',lw=2,label='True')\n",
        "            plt.ylim(0,1.05)\n",
        "            plt.title(f\"Node {i+1}\")\n",
        "            if i==0: plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_nested_activations(self):\n",
        "        plt.figure(figsize=(12,3))\n",
        "        for i,rep in enumerate(self.nested_reps):\n",
        "            plt.subplot(1,self.D_graph,i+1)\n",
        "            plt.bar(range(len(rep)),rep,color=plt.cm.plasma(rep))\n",
        "            plt.ylim(0,1)\n",
        "            plt.title(f\"Node {i+1}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_outer_fuzzy_graph(self):\n",
        "        G = nx.DiGraph()\n",
        "        for i in range(self.D_graph): G.add_node(i)\n",
        "        for i in range(self.D_graph):\n",
        "            for j in range(self.D_graph):\n",
        "                if i!=j and abs(self.chosen_Gmat[i,j])>0.02:\n",
        "                    G.add_edge(i,j,weight=self.chosen_Gmat[i,j])\n",
        "        node_sizes = [self.best_dim_per_node[i]*200 for i in range(self.D_graph)]\n",
        "        edge_colors = ['green' if d['weight']>0 else 'red' for _,_,d in G.edges(data=True)]\n",
        "        edge_widths = [abs(d['weight'])*3 for _,_,d in G.edges(data=True)]\n",
        "        pos = nx.circular_layout(G)\n",
        "        plt.figure(figsize=(6,6))\n",
        "        nx.draw(G,pos,node_size=node_sizes,node_color='skyblue',\n",
        "                edge_color=edge_colors,width=edge_widths,arrows=True,with_labels=True)\n",
        "        plt.title(\"Outer Fuzzy Multiplex Graph\")\n",
        "        plt.show()\n",
        "# ---------------- INTERACTIONS INSPECTOR ----------------\n",
        "    def print_interactions(self, return_tensor=True, verbose=True):\n",
        "        \"\"\"\n",
        "        Build inter-layer activations tensor and optionally print them.\n",
        "\n",
        "        Returns:\n",
        "            inter_tensor: np.ndarray of shape (D_graph, D_graph, inter_dim)\n",
        "                        inter_tensor[i,j,:] contains activations from node i to node j,\n",
        "                        zeros if no edge exists.\n",
        "        \"\"\"\n",
        "        D_graph = self.D_graph\n",
        "        inter_dim = self.inter_layer.inter_dim\n",
        "        inter_tensor = np.zeros((D_graph, D_graph, inter_dim))\n",
        "\n",
        "        acts = self.inter_layer.build_activations(self.chosen_Gmat, self.nested_reps)\n",
        "\n",
        "        if not acts:\n",
        "            if verbose:\n",
        "                print(\"No active edges above threshold.\")\n",
        "            return inter_tensor if return_tensor else None\n",
        "\n",
        "        for (i, j), vec in acts.items():\n",
        "            inter_tensor[i, j, :] = vec\n",
        "            if verbose:\n",
        "                act_str = \", \".join([f\"{v:.3f}\" for v in vec])\n",
        "                print(f\"Node {i} -> Node {j}: [{act_str}]\")\n",
        "\n",
        "        return inter_tensor if return_tensor else None\n",
        "\n",
        "\n",
        "        def print_l2_summary(self):\n",
        "            print(\"\\nL2 Distances to Target per Node:\")\n",
        "\n",
        "# ---------------- USAGE ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    optimizer = GDFCM(\n",
        "        candidate_dims, D_graph,\n",
        "        inner_archive_size, inner_offspring,\n",
        "        outer_archive_size, outer_offspring,\n",
        "        synthetic_targets,\n",
        "        inner_learning, gamma_interlayer=gamma_interlayer,\n",
        "        causal_flag=False\n",
        "    )\n",
        "    metrics_list = optimizer.run()\n",
        "    optimizer.plot_pointwise_minmax_elite()\n",
        "    optimizer.plot_nested_activations()\n",
        "    optimizer.plot_outer_fuzzy_graph()\n",
        "  #  optimizer.print_interactions()\n",
        "    tensor = optimizer.print_interactions()\n",
        "    print(\"Tensor shape:\", tensor.shape,'\\n',tensor)\n",
        "    import matplotlib.pyplot as plt\n",
        "    import networkx as nx\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from mpl_toolkits.mplot3d import Axes3D\n",
        "D_graph = len(optimizer.nested_reps)\n",
        "tensor = optimizer.print_interactions(return_tensor=True, verbose=False)\n",
        "\n",
        "# ---------------- Outer nodes (hubs) ----------------\n",
        "G_outer = nx.DiGraph()\n",
        "for i in range(D_graph):\n",
        "    G_outer.add_node(i)\n",
        "for i in range(D_graph):\n",
        "    for j in range(D_graph):\n",
        "        if i != j and np.any(tensor[i,j,:] != 0):\n",
        "            # Shift to signed weights: 0.5 -> 0, <0.5 negative, >0.5 positive\n",
        "            mean_weight = 2 * (np.mean(tensor[i,j,:]) - 0.5)\n",
        "            G_outer.add_edge(i, j, weight=mean_weight)\n",
        "\n",
        "# Outer spring layout\n",
        "pos_outer_2d = nx.circular_layout(G_outer, scale=5)\n",
        "pos_outer = np.array([[x, y, 0] for x, y in pos_outer_2d.values()])\n",
        "\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot outer nodes\n",
        "for i in range(D_graph):\n",
        "    ax.scatter(*pos_outer[i], s=300, color='skyblue')\n",
        "    ax.text(*pos_outer[i], f'Node {i}', color='black')\n",
        "\n",
        "# Plot outer edges with positive/negative colors\n",
        "\n",
        "for i, j, data in G_outer.edges(data=True):\n",
        "    x_vals = [pos_outer[i,0], pos_outer[j,0]]\n",
        "    y_vals = [pos_outer[i,1], pos_outer[j,1]]\n",
        "    z_vals = [pos_outer[i,2], pos_outer[j,2]]\n",
        "\n",
        "    # Positive = bright green, Negative = bright red\n",
        "    color = 'green' if data['weight'] > 0 else 'red'\n",
        "    linewidth = 2 + 4*abs(data['weight'])  # scale width by magnitude\n",
        "    ax.plot(x_vals, y_vals, z_vals, color=color, linewidth=linewidth)\n",
        "# ---------------- Inner FCMs (small circular around hub) ----------------\n",
        "for i, rep in enumerate(optimizer.nested_reps):\n",
        "    dims = len(rep)\n",
        "    angle = np.linspace(0, 2*np.pi, dims, endpoint=False)\n",
        "    radius = 0.8  # small circle\n",
        "    xs = pos_outer[i,0] + radius * np.cos(angle)\n",
        "    ys = pos_outer[i,1] + radius * np.sin(angle)\n",
        "    zs = pos_outer[i,2] + rep  # activation as height\n",
        "\n",
        "    # Plot inner nodes\n",
        "    ax.scatter(xs, ys, zs, c=rep, cmap='plasma', s=50)\n",
        "\n",
        "    # Connect inner nodes in circle\n",
        "    for k in range(dims):\n",
        "        ax.plot([xs[k], xs[(k+1)%dims]], [ys[k], ys[(k+1)%dims]], [zs[k], zs[(k+1)%dims]], color='gray', alpha=0.5)\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Activation')\n",
        "ax.set_title('Outer Nodes with Inner FCMs (Signed correlations)')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2WARp8-ZamJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from matplotlib.cm import get_cmap\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "candidate_dims = [6] * 3\n",
        "D_graph = 4\n",
        "\n",
        "inner_archive_size = 80\n",
        "inner_offspring = 40\n",
        "outer_archive_size = 40\n",
        "outer_offspring = 40\n",
        "inner_iters_per_outer = 50\n",
        "outer_generations = 101\n",
        "outer_cost_limit = 1000\n",
        "inner_learning = 0.1\n",
        "gamma_interlayer = 0.3\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ---------------------- Neural Nets for Metric Estimation ----------------------\n",
        "class ParamNet(nn.Module):\n",
        "    \"\"\"Estimates W0, T0, U0 from input features.\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
        "        self.out = nn.Linear(hidden_dim // 2, 3)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        raw = self.out(h)\n",
        "        w0 = F.softplus(raw[:, 0])\n",
        "        t0 = F.softplus(raw[:, 1])\n",
        "        u0 = torch.sigmoid(raw[:, 2])\n",
        "        w0 = 10.0 * (1.0 + 0.2 * (w0 - 1.0))\n",
        "        t0 = 100.0 * (1.0 + 0.2 * (t0 - 1.0))\n",
        "        u0 = 1.0 * u0\n",
        "        return torch.stack([w0, t0, u0], dim=1)\n",
        "\n",
        "\n",
        "class PatienceNet(nn.Module):\n",
        "    \"\"\"Estimates patience metric from input features.\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=32):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
        "        self.out = nn.Linear(hidden_dim // 2, 1)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        raw = self.out(h)\n",
        "        patience = torch.sigmoid(raw).squeeze(-1)\n",
        "        return patience\n",
        "\n",
        "\n",
        "# ---------------------- MetricsEvaluator using Neural Estimators ----------------------\n",
        "class MetricsEvaluator:\n",
        "    def __init__(self, data_matrix, param_net: ParamNet, patience_net: PatienceNet, device='cpu'):\n",
        "        self.data_matrix = data_matrix.astype(np.float32)\n",
        "        self.num_features = data_matrix.shape[1]\n",
        "        self.device = device\n",
        "        self.param_net = param_net.to(self.device)\n",
        "        self.patience_net = patience_net.to(self.device)\n",
        "        self.param_net.eval()\n",
        "        self.patience_net.eval()\n",
        "\n",
        "    def compute_node_metrics(self, node_idx, y=None):\n",
        "        \"\"\"Compute metrics for a given node using neural estimators.\"\"\"\n",
        "        row = self.data_matrix[node_idx % self.data_matrix.shape[0]]\n",
        "        row_tensor = torch.from_numpy(row).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            params = self.param_net(row_tensor).cpu().numpy().squeeze(0)\n",
        "            patience_val = float(self.patience_net(row_tensor).cpu().numpy().squeeze(0))\n",
        "\n",
        "        W0_pred, T0_pred, U0_pred = float(params[0]), float(params[1]), float(params[2])\n",
        "\n",
        "        # fallback\n",
        "        if y is None:\n",
        "            y = np.array([0.5, 0.5, 0.5])\n",
        "        else:\n",
        "            y = np.array(y[:3]) if len(y) >= 3 else np.pad(y, (0, 3-len(y)), constant_values=0.5)\n",
        "\n",
        "        # Compute signals\n",
        "        k = self.num_features\n",
        "        base = max(1, k // 3)\n",
        "        wait_signal = np.mean(row[0:base])\n",
        "        throughput_signal = np.mean(row[base:2*base])\n",
        "        util_signal = np.mean(row[2*base:k])\n",
        "\n",
        "        # Metrics\n",
        "        wait = np.clip(W0_pred * (1 + 1.2 * wait_signal + 0.8 * y[0]), 0, 100)\n",
        "        throughput = np.clip(T0_pred * (1 + 1.1 * throughput_signal + 0.6 * y[1] - 0.4 * wait_signal), 0, 150)\n",
        "        util = np.clip(U0_pred + 0.8 * util_signal + 0.6 * y[2], 0, 1)\n",
        "\n",
        "        # Score combining all\n",
        "        score = -wait + throughput + util + patience_val\n",
        "\n",
        "        return {\n",
        "            'wait': float(wait),\n",
        "            'throughput': float(throughput),\n",
        "            'util': float(util),\n",
        "            'patience': patience_val,\n",
        "            'score': float(score),\n",
        "            'W0': W0_pred,\n",
        "            'T0': T0_pred,\n",
        "            'U0': U0_pred\n",
        "        }\n",
        "\n",
        "# ---------------- INTER-LAYER ----------------\n",
        "class InterLayer:\n",
        "    def __init__(self, D_graph, max_inner_dim, inter_dim=None, edge_threshold=0.02, gamma=1.0, seed=42):\n",
        "        np.random.seed(seed)\n",
        "        self.D_graph = D_graph\n",
        "        self.max_input = 2*max_inner_dim\n",
        "        self.edge_threshold = edge_threshold\n",
        "        self.gamma = gamma\n",
        "        self.inter_dim = inter_dim if inter_dim is not None else max_inner_dim\n",
        "        self.weights = {(i,j): np.random.uniform(-0.6,0.6,(self.inter_dim,self.max_input))\n",
        "                        for i in range(D_graph) for j in range(D_graph) if i!=j}\n",
        "        self.bias = {(i,j): np.random.uniform(-0.3,0.3,self.inter_dim)\n",
        "                     for i in range(D_graph) for j in range(D_graph) if i!=j}\n",
        "    # ---------- INTER-LAYER ACTIVATIONS ----------\n",
        "    def print_interactions(self, return_tensor=True, verbose=True):\n",
        "        \"\"\"\n",
        "        Print or return the inter-layer activation tensor.\n",
        "        Shape: (D_graph, D_graph, inter_dim)\n",
        "        \"\"\"\n",
        "        D_graph = self.D_graph\n",
        "        inter_dim = self.inter_layer.inter_dim\n",
        "        inter_tensor = np.zeros((D_graph, D_graph, inter_dim))\n",
        "        acts = self.inter_layer.build_activations(self.chosen_Gmat, self.nested_reps)\n",
        "        if not acts:\n",
        "            if verbose: print(\"No active edges above threshold.\")\n",
        "            return inter_tensor if return_tensor else None\n",
        "        for (i, j), vec in acts.items():\n",
        "            inter_tensor[i, j, :] = vec\n",
        "            if verbose:\n",
        "                act_str = \", \".join([f\"{v:.3f}\" for v in vec])\n",
        "                print(f\"Node {i} -> Node {j}: [{act_str}]\")\n",
        "        return inter_tensor if return_tensor else None\n",
        "\n",
        "    def compute_edge_activation(self, i, j, nested_reps):\n",
        "        concat = np.concatenate([nested_reps[i], nested_reps[j]])\n",
        "        concat = np.pad(concat, (0, max(0,self.max_input-len(concat))))[:self.max_input]\n",
        "        v = self.weights[(i,j)].dot(concat) + self.bias[(i,j)]\n",
        "        return 1/(1+np.exp(-v))\n",
        "\n",
        "    def build_activations(self, Gmat, nested_reps):\n",
        "        acts = {}\n",
        "        for i in range(self.D_graph):\n",
        "            for j in range(self.D_graph):\n",
        "                if i==j: continue\n",
        "                if abs(Gmat[i,j])>self.edge_threshold:\n",
        "                    acts[(i,j)] = self.compute_edge_activation(i,j,nested_reps)\n",
        "        return acts\n",
        "\n",
        "    @staticmethod\n",
        "    def pairwise_squared_corr(acts):\n",
        "        if len(acts)<2: return 0.0\n",
        "        A = np.stack(list(acts.values()))\n",
        "        A_centered = A - A.mean(axis=1,keepdims=True)\n",
        "        stds = np.sqrt(np.sum(A_centered**2,axis=1)/(A.shape[1]-1) + 1e-12)\n",
        "        cov = A_centered @ A_centered.T / (A.shape[1]-1)\n",
        "        corr = cov / (np.outer(stds,stds)+1e-12)\n",
        "        np.fill_diagonal(corr,0)\n",
        "        return float((corr**2).sum())\n",
        "\n",
        "    def mi_for_graph(self, Gmat, nested_reps):\n",
        "        acts = self.build_activations(Gmat,nested_reps)\n",
        "        if not acts: return 0.0\n",
        "        return self.gamma * self.pairwise_squared_corr(acts)\n",
        "\n",
        "# ---------------- GDFCM CLASS ----------------\n",
        "class GDFCM:\n",
        "    def __init__(self, candidate_dims, D_graph, inner_archive_size, inner_offspring,\n",
        "                 outer_archive_size, outer_offspring, synthetic_targets, inner_learning,\n",
        "                 gamma_interlayer=1.0, causal_flag=True):\n",
        "        self.candidate_dims = candidate_dims\n",
        "        self.D_graph = D_graph\n",
        "        self.inner_archive_size = inner_archive_size\n",
        "        self.inner_offspring = inner_offspring\n",
        "        self.outer_archive_size = outer_archive_size\n",
        "        self.outer_offspring = outer_offspring\n",
        "        self.synthetic_targets = synthetic_targets\n",
        "        self.inner_learning = inner_learning\n",
        "        self.causal_flag = causal_flag\n",
        "\n",
        "        self.nested_reps = [np.zeros(max(candidate_dims)) for _ in range(D_graph)]\n",
        "        self.best_dim_per_node = [candidate_dims[0] for _ in range(D_graph)]\n",
        "        self.inter_layer = InterLayer(D_graph, max_inner_dim=max(candidate_dims), gamma=gamma_interlayer)\n",
        "        self.chosen_Gmat = np.random.uniform(-0.5,0.5,(D_graph,D_graph))\n",
        "        np.fill_diagonal(self.chosen_Gmat,0)\n",
        "        self.l2_before, self.l2_after = [], []\n",
        "\n",
        "        # Store capped node metrics for plotting and fuzzy tensor\n",
        "        self.capped_node_metrics = 250\n",
        "\n",
        "    # ---------- INNER LOOP ----------\n",
        "    def run_inner(self, node_idx, target, D_fcm, steps=100, lr_x=0.001, lr_W=0.001):\n",
        "        x = target.copy()\n",
        "        W = np.random.uniform(-0.6,0.6,(D_fcm,D_fcm))\n",
        "        np.fill_diagonal(W,0)\n",
        "        self.l2_before.append(np.linalg.norm(self.nested_reps[node_idx]-target))\n",
        "\n",
        "        for _ in range(steps):\n",
        "            z = W.dot(x)\n",
        "            Theta_grad_z = 2*z - target\n",
        "            Theta_grad_x = Theta_grad_z @ W + 0.5*(x+1)**2\n",
        "            Theta_grad_W = np.outer(Theta_grad_z,x)\n",
        "\n",
        "            x -= lr_x * np.clip(Theta_grad_x,-0.05,0.05)\n",
        "            x = np.clip(x,0,1)\n",
        "            W -= lr_W * np.clip(Theta_grad_W,-0.01,0.01)\n",
        "            np.fill_diagonal(W,0)\n",
        "            W = np.clip(W,-1,1)\n",
        "\n",
        "        self.nested_reps[node_idx] = x\n",
        "        self.l2_after.append(np.linalg.norm(x-target))\n",
        "        mi_score = self.inter_layer.mi_for_graph(self.chosen_Gmat,self.nested_reps)\n",
        "        return x, W, x, mi_score\n",
        "\n",
        "    # ---------- OUTER LOOP ----------\n",
        "    def run_outer(self, outer_cost_limit=100):\n",
        "        metrics_evaluator = MetricsEvaluator(DATA_MATRIX, param_net, patience_net)\n",
        "        node_metrics_list = []\n",
        "        raw_scores = []\n",
        "\n",
        "        # Compute node metrics and collect raw scores\n",
        "        for i, y in enumerate(self.nested_reps):\n",
        "            metrics = metrics_evaluator.compute_node_metrics(i, y=y)\n",
        "            node_metrics_list.append(metrics)\n",
        "            raw_scores.append(metrics['score'])\n",
        "\n",
        "        raw_scores = np.array(raw_scores)\n",
        "        total_raw = raw_scores.sum()\n",
        "\n",
        "        # Apply cap if total exceeds the limit\n",
        "        if total_raw > outer_cost_limit:\n",
        "            scale_factor = outer_cost_limit / total_raw\n",
        "            # Scale all metrics proportionally\n",
        "            for i, metrics in enumerate(node_metrics_list):\n",
        "                for key in ['wait', 'throughput', 'util', 'patience', 'score']:\n",
        "                    metrics[key] *= scale_factor\n",
        "            total_capped = outer_cost_limit\n",
        "        else:\n",
        "            total_capped = total_raw\n",
        "\n",
        "        # Store capped node metrics for plotting/tensors\n",
        "        self.capped_node_metrics = node_metrics_list\n",
        "\n",
        "        return node_metrics_list, total_capped\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # ---------- FULL RUN ----------\n",
        "    def run(self, outer_generations=101, outer_cost_limit=1000):\n",
        "        \"\"\"\n",
        "        Full optimization run over outer generations.\n",
        "        Prints node metrics with capped scores and outer total capped score.\n",
        "        \"\"\"\n",
        "        final_metrics = None\n",
        "\n",
        "        for gen in range(outer_generations):\n",
        "            mi_scores = []\n",
        "            # --- Inner loop per node ---\n",
        "            for node_idx in range(self.D_graph):\n",
        "                dim = self.best_dim_per_node[node_idx]\n",
        "                target = self.synthetic_targets[node_idx][dim]\n",
        "                _, _, _, mi_score = self.run_inner(node_idx, target, dim)\n",
        "                mi_scores.append(mi_score)\n",
        "\n",
        "            # --- Outer loop with capping ---\n",
        "            metrics_list, capped_score = self.run_outer(outer_cost_limit=outer_cost_limit)\n",
        "\n",
        "            # --- Print capped metrics ---\n",
        "            print(f\"\\n--- Generation {gen} Metrics ---\")\n",
        "            for i, m in enumerate(metrics_list):\n",
        "                print(\n",
        "                    f\"Node {i} | \"\n",
        "                    + \" | \".join([f\"{k}: {v:.2f}\" for k, v in m.items()])\n",
        "                )\n",
        "            print(f\"Outer Score (capped): {capped_score:.3f}\")\n",
        "\n",
        "            final_metrics = metrics_list\n",
        "\n",
        "        return final_metrics\n",
        "\n",
        "\n",
        "    # ---------- PLOTTING FUNCTIONS USE CAPPED METRICS ----------\n",
        "    def _get_metrics_for_plotting(self, i):\n",
        "        # Return capped metrics if available\n",
        "        if self.capped_node_metrics is not None:\n",
        "            return self.capped_node_metrics[i]\n",
        "        metrics_evaluator = MetricsEvaluator(DATA_MATRIX)\n",
        "        return metrics_evaluator.compute_node_metrics(i, y=self.nested_reps[i])\n",
        "\n",
        "    def plot_metric_dashboard_colored(self):\n",
        "        metrics_keys = ['wait', 'throughput', 'util', 'patience']\n",
        "        D_graph = self.D_graph\n",
        "        metric_matrix = np.zeros((D_graph, len(metrics_keys)))\n",
        "        for i in range(D_graph):\n",
        "            metrics = self._get_metrics_for_plotting(i)\n",
        "            metric_matrix[i, :] = [metrics[k] for k in metrics_keys]\n",
        "\n",
        "        metric_norm = (metric_matrix - metric_matrix.min(axis=0)) / (np.ptp(metric_matrix, axis=0) + 1e-12)\n",
        "        cmap = get_cmap(\"viridis\")\n",
        "\n",
        "        fig, axes = plt.subplots(3, 1, figsize=(12, 8), gridspec_kw={'height_ratios':[1,1,1]})\n",
        "\n",
        "        bottoms = np.zeros(D_graph)\n",
        "        for idx, key in enumerate(metrics_keys):\n",
        "            colors = [cmap(val) for val in metric_norm[:, idx]]\n",
        "            axes[0].bar(range(D_graph), metric_matrix[:, idx], bottom=bottoms, color=colors,\n",
        "                        edgecolor='black', label=key)\n",
        "            bottoms += metric_matrix[:, idx]\n",
        "        axes[0].set_xticks(range(D_graph))\n",
        "        axes[0].set_xticklabels([f\"Node {i+1}\" for i in range(D_graph)])\n",
        "        axes[0].set_ylabel(\"Metric Value (Stacked)\")\n",
        "        axes[0].set_title(\"Stacked Node Metrics (Color by Intensity)\")\n",
        "        axes[0].legend(loc='upper right')\n",
        "\n",
        "        for i, rep in enumerate(self.nested_reps):\n",
        "            axes[1].plot(range(len(rep)), rep + i*1.1, '-o', label=f\"Node {i+1}\")\n",
        "        axes[1].set_ylabel(\"Nested Reps (shifted)\")\n",
        "        axes[1].set_title(\"Nested Representations per Node\")\n",
        "        axes[1].legend(loc='upper right')\n",
        "\n",
        "        sns.heatmap(metric_matrix, annot=True, fmt=\".2f\", cmap=\"viridis\",\n",
        "                    yticklabels=[f\"Node {i+1}\" for i in range(D_graph)],\n",
        "                    xticklabels=metrics_keys, ax=axes[2])\n",
        "        axes[2].set_title(\"Node Metrics Heatmap\")\n",
        "        axes[2].set_xlabel(\"Metrics\")\n",
        "        axes[2].set_ylabel(\"Nodes\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_activations_and_metrics(self, normalize_activations=True):\n",
        "        metrics_keys = ['wait', 'throughput', 'util', 'patience']\n",
        "        D_graph = self.D_graph\n",
        "        metric_matrix = np.zeros((D_graph, len(metrics_keys)))\n",
        "        for i in range(D_graph):\n",
        "            metrics = self._get_metrics_for_plotting(i)\n",
        "            metric_matrix[i, :] = [metrics[k] for k in metrics_keys]\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        for i, rep in enumerate(self.nested_reps):\n",
        "            rep_vals = np.array(rep)\n",
        "            rep_vals_norm = (rep_vals - rep_vals.min()) / (np.ptp(rep_vals) + 1e-12) if normalize_activations else rep_vals\n",
        "            colors = plt.cm.plasma(rep_vals_norm)\n",
        "\n",
        "            plt.subplot(2, D_graph, i+1)\n",
        "            plt.bar(range(len(rep_vals)), rep_vals, color=colors, edgecolor='black')\n",
        "            plt.ylim(0, 1 if normalize_activations else rep_vals.max()*1.1)\n",
        "            plt.title(f\"Node {i+1} Activations\")\n",
        "            plt.xlabel(\"Dimension\")\n",
        "            plt.ylabel(\"Value\")\n",
        "\n",
        "            plt.subplot(2, D_graph, i+1+D_graph)\n",
        "            plt.bar(range(len(metrics_keys)), metric_matrix[i, :],\n",
        "                    color=plt.cm.viridis(metric_matrix[i,:]/(metric_matrix[i,:].max()+1e-12)), edgecolor='black')\n",
        "            plt.ylim(0, metric_matrix.max()*1.1)\n",
        "            plt.xticks(range(len(metrics_keys)), metrics_keys, rotation=45)\n",
        "            plt.title(f\"Node {i+1} Metrics\")\n",
        "            plt.ylabel(\"Value\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_activations_and_metrics_n(self, normalize_activations=True, normalize_metrics=True):\n",
        "        metrics_keys = ['wait', 'throughput', 'util', 'patience']\n",
        "        D_graph = self.D_graph\n",
        "        metric_matrix = np.zeros((D_graph, len(metrics_keys)))\n",
        "        for i in range(D_graph):\n",
        "            metrics = self._get_metrics_for_plotting(i)\n",
        "            metric_matrix[i, :] = [metrics[k] for k in metrics_keys]\n",
        "\n",
        "        metric_matrix_norm = (metric_matrix - metric_matrix.min()) / (np.ptp(metric_matrix) + 1e-12) if normalize_metrics else metric_matrix\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        for i, rep in enumerate(self.nested_reps):\n",
        "            rep_vals = np.array(rep)\n",
        "            rep_vals_norm = (rep_vals - rep_vals.min()) / (np.ptp(rep_vals) + 1e-12) if normalize_activations else rep_vals\n",
        "            colors = plt.cm.plasma(rep_vals_norm)\n",
        "\n",
        "            plt.subplot(2, D_graph, i+1)\n",
        "            plt.bar(range(len(rep_vals)), rep_vals, color=colors, edgecolor='black')\n",
        "            plt.ylim(0, 1 if normalize_activations else rep_vals.max()*1.1)\n",
        "            plt.title(f\"Node {i+1} Activations\")\n",
        "            plt.xlabel(\"Dimension\")\n",
        "            plt.ylabel(\"Value\")\n",
        "\n",
        "            plt.subplot(2, D_graph, i+1+D_graph)\n",
        "            plt.bar(range(len(metrics_keys)), metric_matrix[i, :],\n",
        "                    color=plt.cm.viridis(metric_matrix_norm[i, :]), edgecolor='black')\n",
        "            plt.ylim(0, 1 if normalize_metrics else metric_matrix.max()*1.1)\n",
        "            plt.xticks(range(len(metrics_keys)), metrics_keys, rotation=45)\n",
        "            plt.title(f\"Node {i+1} Metrics\")\n",
        "            plt.ylabel(\"Value\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Other plotting methods can similarly call self._get_metrics_for_plotting(i)\n",
        "\n",
        "    def plot_activations_and_metrics_n(self, normalize_activations=True, normalize_metrics=True):\n",
        "        \"\"\"\n",
        "        Plot per-node bar plots for:\n",
        "        1. Nested activations (colored bars)\n",
        "        2. Metrics ('wait', 'throughput', 'util', 'patience') normalized across all nodes\n",
        "        \"\"\"\n",
        "        metrics_evaluator = MetricsEvaluator(DATA_MATRIX, param_net, patience_net)\n",
        "        metrics_keys = ['wait', 'throughput', 'util', 'patience']\n",
        "        D_graph = self.D_graph\n",
        "\n",
        "        # Collect metrics for all nodes\n",
        "        metric_matrix = np.zeros((D_graph, len(metrics_keys)))\n",
        "        for i, rep in enumerate(self.nested_reps):\n",
        "            metrics = metrics_evaluator.compute_node_metrics(i, y=rep)\n",
        "            metric_matrix[i, :] = [metrics[k] for k in metrics_keys]\n",
        "\n",
        "        # Normalize metrics across all nodes & metrics\n",
        "        if normalize_metrics:\n",
        "            metric_matrix_norm = (metric_matrix - metric_matrix.min()) / (np.ptp(metric_matrix) + 1e-12)\n",
        "        else:\n",
        "            metric_matrix_norm = metric_matrix\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        for i, rep in enumerate(self.nested_reps):\n",
        "            # --- Nested activations bar ---\n",
        "            rep_vals = np.array(rep)\n",
        "            if normalize_activations:\n",
        "                rep_vals_norm = (rep_vals - rep_vals.min()) / (np.ptp(rep_vals) + 1e-12)\n",
        "            else:\n",
        "                rep_vals_norm = rep_vals\n",
        "            colors = plt.cm.plasma(rep_vals_norm)\n",
        "\n",
        "            plt.subplot(2, D_graph, i+1)\n",
        "            plt.bar(range(len(rep_vals)), rep_vals, color=colors, edgecolor='black')\n",
        "            plt.ylim(0, 1 if normalize_activations else rep_vals.max()*1.1)\n",
        "            plt.title(f\"Node {i+1} Activations\")\n",
        "            plt.xlabel(\"Dimension\")\n",
        "            plt.ylabel(\"Value\")\n",
        "\n",
        "            # --- Metrics bar (normalized across all nodes) ---\n",
        "            plt.subplot(2, D_graph, i+1+D_graph)\n",
        "            plt.bar(range(len(metrics_keys)), metric_matrix[i, :],\n",
        "                    color=plt.cm.viridis(metric_matrix_norm[i, :]), edgecolor='black')\n",
        "            plt.ylim(0, 1 if normalize_metrics else metric_matrix.max()*1.1)\n",
        "            plt.xticks(range(len(metrics_keys)), metrics_keys, rotation=45)\n",
        "            plt.title(f\"Node {i+1} Metrics\")\n",
        "            plt.ylabel(\"Value\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    def compute_fuzzy_metric_tensor(self, normalize=True, verbose=False):\n",
        "        \"\"\"\n",
        "        Compute a fuzzy metric tensor for all node pairs (D_graph x D_graph x num_metrics),\n",
        "        where each slice [i,j,:] contains metrics of node j (or combined metrics of i->j),\n",
        "        optionally normalized across all nodes and metrics.\n",
        "        \"\"\"\n",
        "        metrics_evaluator = MetricsEvaluator(DATA_MATRIX, param_net, patience_net)\n",
        "        metrics_keys = ['wait', 'throughput', 'util', 'patience']\n",
        "        D_graph = self.D_graph\n",
        "        num_metrics = len(metrics_keys)\n",
        "\n",
        "        tensor = np.zeros((D_graph, D_graph, num_metrics))\n",
        "\n",
        "        # Compute metric vector for each node\n",
        "        node_metrics = []\n",
        "        for i, rep in enumerate(self.nested_reps):\n",
        "            metrics = metrics_evaluator.compute_node_metrics(i, y=rep)\n",
        "            node_metrics.append(np.array([metrics[k] for k in metrics_keys]))\n",
        "\n",
        "        node_metrics = np.array(node_metrics)  # shape: (D_graph, num_metrics)\n",
        "\n",
        "        # Fill tensor: optionally weighted by edge strength in chosen_Gmat\n",
        "        for i in range(D_graph):\n",
        "            for j in range(D_graph):\n",
        "                if i == j:\n",
        "                    tensor[i, j, :] = node_metrics[j]  # self-metrics\n",
        "                else:\n",
        "                    weight = np.clip(abs(self.chosen_Gmat[i,j]), 0, 1)  # optional fuzzy weight\n",
        "                    tensor[i, j, :] = weight * node_metrics[j]\n",
        "\n",
        "        # Normalize tensor across all values (0-1)\n",
        "        if normalize:\n",
        "            tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min() + 1e-12)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Fuzzy Metric Tensor shape:\", tensor.shape)\n",
        "            for i in range(D_graph):\n",
        "                for j in range(D_graph):\n",
        "                    print(f\"Node {i} -> Node {j} metrics:\", tensor[i,j,:])\n",
        "\n",
        "        return tensor\n",
        "    def compute_fuzzy_metric_tensor_bounds(self, verbose=False):\n",
        "        \"\"\"\n",
        "        Compute a fuzzy metric tensor with lower and upper bounds per node pair.\n",
        "        Uses capped metrics if available.\n",
        "        Returns tensor of shape (D_graph, D_graph, num_metrics, 2)\n",
        "        where [:,:,:,0] = lower, [:,:,:,1] = upper.\n",
        "        \"\"\"\n",
        "        metrics_keys = ['wait', 'throughput', 'util', 'patience']\n",
        "        D_graph = self.D_graph\n",
        "        num_metrics = len(metrics_keys)\n",
        "\n",
        "        tensor = np.zeros((D_graph, D_graph, num_metrics, 2))  # last dim: [lower, upper]\n",
        "\n",
        "        # Use capped metrics if they exist\n",
        "        if hasattr(self, 'capped_node_metrics') and self.capped_node_metrics is not None:\n",
        "            node_metrics = np.array([[m[k] for k in metrics_keys] for m in self.capped_node_metrics])\n",
        "        else:\n",
        "            # fallback to raw metrics\n",
        "            metrics_evaluator = MetricsEvaluator(DATA_MATRIX, param_net, patience_net)\n",
        "            node_metrics = np.array([\n",
        "                [metrics_evaluator.compute_node_metrics(i, y=self.nested_reps[i])[k] for k in metrics_keys]\n",
        "                for i in range(D_graph)\n",
        "            ])\n",
        "\n",
        "        # Fuzzy bounds: for example 10% around the metric value\n",
        "        fuzz_factor = 0.1\n",
        "        for i in range(D_graph):\n",
        "            for j in range(D_graph):\n",
        "                metrics_j = node_metrics[j]\n",
        "                lower = np.clip(metrics_j * (1 - fuzz_factor), 0, None)\n",
        "                upper = metrics_j * (1 + fuzz_factor)\n",
        "                tensor[i, j, :, 0] = lower\n",
        "                tensor[i, j, :, 1] = upper\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Fuzzy Metric Tensor shape (with bounds):\", tensor.shape)\n",
        "\n",
        "        return tensor\n",
        "\n",
        "    def plot_fuzzy_metric_tensor(self, fuzzy_tensor, metrics_keys=['wait','throughput','util','patience']):\n",
        "        \"\"\"\n",
        "        Plot a visualization of the Fuzzy Metric Tensor (FMT) with lower/upper bounds.\n",
        "\n",
        "        fuzzy_tensor: np.ndarray of shape (D_graph, D_graph, num_metrics, 2)\n",
        "                    last dimension = [lower, upper]\n",
        "        \"\"\"\n",
        "        D_graph = self.D_graph\n",
        "        num_metrics = len(metrics_keys)\n",
        "\n",
        "        fig, axes = plt.subplots(1, num_metrics, figsize=(4*num_metrics, 4))\n",
        "\n",
        "        for k in range(num_metrics):\n",
        "            lower = fuzzy_tensor[:,:,k,0]\n",
        "            upper = fuzzy_tensor[:,:,k,1]\n",
        "\n",
        "            # Create a fuzzy range heatmap: color = mean, alpha = range/mean\n",
        "            mean_vals = (lower + upper)/2\n",
        "            range_vals = upper - lower\n",
        "            # Normalize range for transparency\n",
        "            max_range = range_vals.max() if range_vals.max()>0 else 1.0\n",
        "            alphas = 0.2 + 0.8 * range_vals / max_range  # alpha 0.21.0\n",
        "\n",
        "            # Plot mean as heatmap\n",
        "            im = axes[k].imshow(mean_vals, cmap='viridis', vmin=0, vmax=mean_vals.max())\n",
        "\n",
        "            # Overlay range as transparency mask\n",
        "            for i in range(D_graph):\n",
        "                for j in range(D_graph):\n",
        "                    alpha_val = np.clip(1 - alphas[i,j], 0.0, 1.0)\n",
        "\n",
        "                    rect = plt.Rectangle((j-0.5, i-0.5), 1, 1, color='white', alpha=alpha_val)\n",
        "\n",
        "                    #rect = plt.Rectangle((j-0.5, i-0.5), 1, 1, color='white', alpha=1-alphas[i,j])\n",
        "                    axes[k].add_patch(rect)\n",
        "                    # Annotate with bounds\n",
        "                    axes[k].text(j, i, f\"{lower[i,j]:.1f}\\n{upper[i,j]:.1f}\", color='black',\n",
        "                                ha='center', va='center', fontsize=9)\n",
        "\n",
        "            axes[k].set_title(f\"FMT - {metrics_keys[k]}\")\n",
        "            axes[k].set_xticks(range(D_graph))\n",
        "            axes[k].set_xticklabels([f\"Node {i+1}\" for i in range(D_graph)])\n",
        "            axes[k].set_yticks(range(D_graph))\n",
        "            axes[k].set_yticklabels([f\"Node {i+1}\" for i in range(D_graph)])\n",
        "\n",
        "        fig.colorbar(im, ax=axes, orientation='vertical', fraction=0.025, pad=0.04, label='Mean Metric Value')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# ---------------- VISUALIZATIONS ----------------\n",
        "# 1. Pointwise min/max elite vs. true targets\n",
        "# ---------------- CONFIG ----------------\n",
        "candidate_dims = [6] * 3\n",
        "D_graph = 4\n",
        "inner_archive_size = 80\n",
        "inner_offspring = 40\n",
        "outer_archive_size = 40\n",
        "outer_offspring = 40\n",
        "inner_learning = 0.1\n",
        "gamma_interlayer = 0.3\n",
        "outer_generations = 10  # for faster testing\n",
        "outer_cost_limit = 1000\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# ---------------- INSTANTIATE OPTIMIZER ----------------\n",
        "optimizer = GDFCM(\n",
        "    candidate_dims=candidate_dims,\n",
        "    D_graph=D_graph,\n",
        "    inner_archive_size=inner_archive_size,\n",
        "    inner_offspring=inner_offspring,\n",
        "    outer_archive_size=outer_archive_size,\n",
        "    outer_offspring=outer_offspring,\n",
        "    synthetic_targets=synthetic_targets,\n",
        "    inner_learning=inner_learning,\n",
        "    gamma_interlayer=gamma_interlayer,\n",
        "\n",
        "    causal_flag=False\n",
        ")\n",
        "\n",
        "# ---------------- RUN FULL OPTIMIZATION ----------------\n",
        "metrics_list = optimizer.run(outer_generations=outer_generations)\n",
        "\n",
        "\n",
        "# 3. Inter-layer activations tensor\n",
        "#tensor = optimizer.print_interactions(return_tensor=True)\n",
        "print(\"Inter-layer activation tensor shape:\", tensor.shape)\n",
        "print(tensor)\n",
        "\n",
        "# 4. Full metric dashboard (colored stacked bars + nested reps + heatmap)\n",
        "optimizer.plot_metric_dashboard_colored()\n",
        "optimizer.plot_activations_and_metrics(normalize_activations=True)\n",
        "\n",
        "# Simple bar plots of activations per node\n",
        "optimizer.plot_activations_and_metrics_n(normalize_activations=True, normalize_metrics=True)\n",
        "fuzzy_metric_tensor = optimizer.compute_fuzzy_metric_tensor_bounds(verbose=False)\n",
        "optimizer.plot_fuzzy_metric_tensor(fuzzy_metric_tensor)\n",
        "\n",
        "#o#ptimizer.plot_activations_bar(normalize=True)\n"
      ],
      "metadata": {
        "id": "espbb7kTbhwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_tensor = optimizer.compute_fuzzy_metric_tensor(normalize=False, verbose=True)\n",
        "print(\"Metric tensor shape:\", metric_tensor.shape)\n",
        "\n",
        "\n",
        "fuzzy_metric_tensor = optimizer.compute_fuzzy_metric_tensor_bounds(verbose=False)\n",
        "print(\"Fuzzy metric tensor shape:\", fuzzy_metric_tensor.shape)\n",
        "\n",
        "fuzzy_metric_tensor"
      ],
      "metadata": {
        "id": "EscpYW1LeEND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fuzzy_metric_tensor = optimizer.compute_fuzzy_metric_tensor_bounds(verbose=False)\n",
        "optimizer.plot_fuzzy_metric_tensor(fuzzy_metric_tensor)\n"
      ],
      "metadata": {
        "id": "b_INau8UgaW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nfzrfrgLga-i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}